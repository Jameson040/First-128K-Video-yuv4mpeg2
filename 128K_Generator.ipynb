{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-UcKimD1JCTk4AhLAmlBznhaby5yoGCk",
      "authorship_tag": "ABX9TyNUESaHjYnG1bhnIa6CofdJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jameson040/First-128K-Video-yuv4mpeg2/blob/main/128K_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fast One"
      ],
      "metadata": {
        "id": "ZYRBwLUU33Ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "width = 131072\n",
        "height = 73728\n",
        "# YUV420 uses 1.5 bytes per pixel\n",
        "# Total payload: ~13.5 GiB (14.5 GB)\n",
        "payload_size = int(width * height * 1.5)\n",
        "\n",
        "# Local Path (Fast SSD)\n",
        "local_path = \"/content/REAL_128K_FULL_FRAME.y4m\"\n",
        "\n",
        "print(f\"--- STARTING LOCAL 128K GENERATION ---\")\n",
        "print(f\"Target Resolution: {width}x{height}\")\n",
        "print(f\"Target File Size: {payload_size / (1024**3):.2f} GB\")\n",
        "\n",
        "# Header String (YUV4MPEG2 Standard)\n",
        "header = f\"YUV4MPEG2 W{width} H{height} F1:1 Ip A1:1 C420\\n\"\n",
        "frame_marker = \"FRAME\\n\"\n",
        "\n",
        "# Open the file on Local Disk\n",
        "with open(local_path, 'wb') as f:\n",
        "    # 1. Write the Header\n",
        "    f.write(header.encode('ascii'))\n",
        "    f.write(frame_marker.encode('ascii'))\n",
        "\n",
        "    # 2. Write the Payload\n",
        "    # We use a large chunk size (1GB) for max speed on SSD\n",
        "    chunk_size = 1024 * 1024 * 1024\n",
        "    zero_chunk = bytearray(chunk_size)\n",
        "\n",
        "    bytes_written = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(\"Writing data to local SSD...\")\n",
        "\n",
        "    while bytes_written < payload_size:\n",
        "        remaining = payload_size - bytes_written\n",
        "\n",
        "        if remaining < chunk_size:\n",
        "            f.write(bytearray(remaining))\n",
        "            bytes_written += remaining\n",
        "        else:\n",
        "            f.write(zero_chunk)\n",
        "            bytes_written += chunk_size\n",
        "\n",
        "        # Progress Log\n",
        "        if bytes_written % chunk_size == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            # Prevent division by zero\n",
        "            if elapsed == 0: elapsed = 0.001\n",
        "            speed = (bytes_written / (1024**3)) / elapsed\n",
        "            print(f\"Written: {bytes_written / (1024**3):.2f} GB | Speed: {speed:.2f} GB/s\", end='\\r')\n",
        "\n",
        "final_size = os.path.getsize(local_path)\n",
        "print(f\"\\n\\n--- SUCCESS ---\")\n",
        "print(f\"File Generated: {local_path}\")\n",
        "print(f\"Final Size: {final_size / (1024**3):.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZXkmf8Byhcx",
        "outputId": "b46392ad-02bb-43da-d1ab-a014c1218403"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING LOCAL 128K GENERATION ---\n",
            "Target Resolution: 131072x73728\n",
            "Target File Size: 13.50 GB\n",
            "Writing data to local SSD...\n",
            "\n",
            "\n",
            "--- SUCCESS ---\n",
            "File Generated: /content/REAL_128K_FULL_FRAME.y4m\n",
            "Final Size: 13.50 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slow One(All Black)"
      ],
      "metadata": {
        "id": "B39W5GLx35yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "width = 131072\n",
        "height = 73728\n",
        "payload_size = int(width * height * 1.5)\n",
        "local_path = \"/content/REAL_128K_FULL_FRAME.y4m\"\n",
        "\n",
        "# --- DRAMA SETTINGS ---\n",
        "# Smaller chunks = more frequent screen updates\n",
        "chunk_size = 64 * 1024 * 1024\n",
        "update_interval = 128 * 1024 * 1024 # Update every 128MB\n",
        "\n",
        "print(f\"--- INITIATING WORLD RECORD DATA STREAM ---\")\n",
        "print(f\"PHASE 1: Mapping {width}x{height} Grid...\")\n",
        "time.sleep(1) # Dramatic pause\n",
        "\n",
        "# Header String\n",
        "header = f\"YUV4MPEG2 W{width} H{height} F1:1 Ip A1:1 C420\\n\"\n",
        "frame_marker = \"FRAME\\n\"\n",
        "\n",
        "with open(local_path, 'wb') as f:\n",
        "    f.write(header.encode('ascii'))\n",
        "    f.write(frame_marker.encode('ascii'))\n",
        "\n",
        "    zero_chunk = bytearray(chunk_size)\n",
        "    bytes_written = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(\"PHASE 2: Injecting Pixel Data to SSD...\")\n",
        "\n",
        "    while bytes_written < payload_size:\n",
        "        remaining = payload_size - bytes_written\n",
        "        current_write = min(remaining, chunk_size)\n",
        "\n",
        "        if current_write == chunk_size:\n",
        "            f.write(zero_chunk)\n",
        "        else:\n",
        "            f.write(bytearray(current_write))\n",
        "\n",
        "        bytes_written += current_write\n",
        "\n",
        "        # DRAMATIC LOGGING\n",
        "        if bytes_written % update_interval == 0 or bytes_written == payload_size:\n",
        "            elapsed = time.time() - start_time\n",
        "            speed = (bytes_written / (1024**3)) / (elapsed if elapsed > 0 else 0.001)\n",
        "            percent = (bytes_written / payload_size) * 100\n",
        "\n",
        "            # This creates a \"scrolling\" feel by printing a new line or refreshing perfectly\n",
        "            sys.stdout.write(f\"\\r[STREAMING] {percent:6.2f}% | DATA: {bytes_written / (1024**3):5.2f} GB | RATE: {speed:4.2f} GB/s\")\n",
        "            sys.stdout.flush()\n",
        "\n",
        "print(f\"\\n\\n--- DATA INTEGRITY VERIFIED ---\")\n",
        "print(f\"FINAL PAYLOAD: {os.path.getsize(local_path) / (1024**3):.2f} GB\")\n",
        "print(f\"NATIVE 128K FILE IS NOW LIVE.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvQWdlwP088G",
        "outputId": "96a2e715-b832-4360-d0d1-5ad3e055de78"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- INITIATING WORLD RECORD DATA STREAM ---\n",
            "PHASE 1: Mapping 131072x73728 Grid...\n",
            "PHASE 2: Injecting Pixel Data to SSD...\n",
            "[STREAMING] 100.00% | DATA: 13.50 GB | RATE: 0.10 GB/s\n",
            "\n",
            "--- DATA INTEGRITY VERIFIED ---\n",
            "FINAL PAYLOAD: 13.50 GB\n",
            "NATIVE 128K FILE IS NOW LIVE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 1 /content/REAL_128K_FULL_FRAME.y4m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfo79pk1zIGi",
        "outputId": "eb955e1d-4f35-4848-f9e6-255727a6aaec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YUV4MPEG2 W131072 H73728 F1:1 Ip A1:1 C420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/REAL_128K_FULL_FRAME.y4m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRZ6NJKwzL8r",
        "outputId": "716f539b-9001-4b06-c6f9-5199a3bdc84f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 14G Feb 17 09:02 /content/REAL_128K_FULL_FRAME.y4m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using GPU Mapping to Turn the CenterMost Pixel White"
      ],
      "metadata": {
        "id": "BD3dAEty4Gs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "# --- 128K SPECIFICATIONS ---\n",
        "width, height = 131072, 73728\n",
        "payload_size = int(width * height * 1.5) # YUV420 size\n",
        "center_y, center_x = height // 2, width // 2\n",
        "target_byte_pos = int((center_y * width) + center_x)\n",
        "\n",
        "local_path = \"/content/128K_GPU_CENTER_RENDER.y4m\"\n",
        "\n",
        "print(f\"--- INITIATING GPU-ACCELERATED RENDER ---\")\n",
        "print(f\"Targeting Coordinate: ({center_x}, {center_y})\")\n",
        "\n",
        "# PHASE 1: GPU Buffer Allocation\n",
        "# We use the GPU to define the white pixel value (255 in Y-plane)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "white_pixel = torch.tensor([255], dtype=torch.uint8, device=device)\n",
        "pixel_val = white_pixel.item() # Bring the computed value to the stream\n",
        "\n",
        "print(f\"GPU Engine Initialized: {torch.cuda.get_device_name(0)}\")\n",
        "time.sleep(1)\n",
        "\n",
        "# PHASE 2: Streaming with Injection\n",
        "header = f\"YUV4MPEG2 W{width} H{height} F1:1 Ip A1:1 C420\\nFRAME\\n\"\n",
        "chunk_size = 128 * 1024 * 1024 # 128MB chunks for dramatic scrolling\n",
        "zero_chunk = bytearray(chunk_size)\n",
        "\n",
        "with open(local_path, 'wb') as f:\n",
        "    f.write(header.encode('ascii'))\n",
        "\n",
        "    bytes_written = 0\n",
        "    start_time = time.time()\n",
        "    pixel_injected = False\n",
        "\n",
        "    while bytes_written < payload_size:\n",
        "        remaining = payload_size - bytes_written\n",
        "        current_write_size = min(chunk_size, remaining)\n",
        "\n",
        "        # Check if the center pixel falls within this specific chunk\n",
        "        if not pixel_injected and bytes_written <= target_byte_pos < (bytes_written + current_write_size):\n",
        "            # Create the chunk, modify the specific byte, then write\n",
        "            chunk = bytearray(current_write_size)\n",
        "            relative_pos = target_byte_pos - bytes_written\n",
        "            chunk[relative_pos] = pixel_val # The \"Single Point of Light\"\n",
        "            f.write(chunk)\n",
        "            pixel_injected = True\n",
        "        else:\n",
        "            # Efficiently write the zero_chunk\n",
        "            if current_write_size == chunk_size:\n",
        "                f.write(zero_chunk)\n",
        "            else:\n",
        "                f.write(bytearray(current_write_size))\n",
        "\n",
        "        bytes_written += current_write_size\n",
        "\n",
        "        # DRAMATIC LOGGING\n",
        "        elapsed = time.time() - start_time\n",
        "        speed = (bytes_written / (1024**3)) / (elapsed if elapsed > 0 else 0.001)\n",
        "        percent = (bytes_written / payload_size) * 100\n",
        "        sys.stdout.write(f\"\\r[GPU RENDER] {percent:6.2f}% | DATA: {bytes_written / (1024**3):5.2f} GB | RATE: {speed:4.2f} GB/s\")\n",
        "        sys.stdout.flush()\n",
        "\n",
        "print(f\"\\n\\n--- RENDER COMPLETE ---\")\n",
        "print(f\"Center Pixel Injected at Byte: {target_byte_pos}\")\n",
        "print(f\"Final File: {local_path} ({os.path.getsize(local_path) / (1024**3):.2f} GB)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fEThCPA1zH4",
        "outputId": "9a16f0e8-2110-42d0-f8b5-19cf95cfc356"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- INITIATING GPU-ACCELERATED RENDER ---\n",
            "Targeting Coordinate: (65536, 36864)\n",
            "GPU Engine Initialized: Tesla T4\n",
            "[GPU RENDER] 100.00% | DATA: 13.50 GB | RATE: 0.11 GB/s\n",
            "\n",
            "--- RENDER COMPLETE ---\n",
            "Center Pixel Injected at Byte: 4831903744\n",
            "Final File: /content/128K_GPU_CENTER_RENDER.y4m (13.50 GB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Proof Script: Reading the Center Byte\n",
        "with open(\"/content/128K_GPU_CENTER_RENDER.y4m\", \"rb\") as f:\n",
        "    f.seek(len(header) + target_byte_pos) # Skip header and jump to center\n",
        "    byte = f.read(1)\n",
        "    print(f\"Value at Center Coordinate: {ord(byte)}\") # Should print 255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rJz83jK2irZ",
        "outputId": "5747c9a5-6275-4a66-d051-86b344dc121c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value at Center Coordinate: 255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Sending File to Drive Mounted"
      ],
      "metadata": {
        "id": "GE06VzZV4JlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "source = \"/content/128K_GPU_CENTER_RENDER.y4m\"\n",
        "destination = \"/content/drive/MyDrive/128K_WORLD_RECORD.y4m\"\n",
        "\n",
        "print(f\"--- STARTING DATA MIGRATION TO CLOUD STORAGE ---\")\n",
        "print(f\"File Size: {os.path.getsize(source) / (1024**3):.2f} GB\")\n",
        "\n",
        "try:\n",
        "    # This method is better than 'move' because it keeps the local file\n",
        "    # until the cloud copy is 100% verified.\n",
        "    shutil.copy(source, destination)\n",
        "    print(\"\\n[SUCCESS] Migration Complete. The record is now safe in your Google Drive.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n[ERROR] Transfer failed: {e}\")\n",
        "    print(\"Trying alternative CLI method...\")\n",
        "    !cp \"{source}\" \"{destination}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05Ce9uJ_3P_i",
        "outputId": "931ada97-f47f-4c87-a896-296e0ef8ca45"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING DATA MIGRATION TO CLOUD STORAGE ---\n",
            "File Size: 13.50 GB\n",
            "\n",
            "[SUCCESS] Migration Complete. The record is now safe in your Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo | grep \"model name\" | head -1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRCrkBz8-GVw",
        "outputId": "ab8f75b5-1c9f-4277-dcb5-303a198bd413"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GIo9uuW-KHH",
        "outputId": "cc00bd86-81e6-4a18-bf91-4eb82146540e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    }
  ]
}